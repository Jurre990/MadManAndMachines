{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import inspect\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\vd00r/.cache\\torch\\hub\\huggingface_pytorch-transformers_main\n",
      "c:\\Users\\vd00r\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "model_bert = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_index = [\"N\",\"E-2\", \"E-3\", \"E-4\", \"E-5\", \"E-6\", \"E-7\", \"E-8\", \"C-1\", \"C-2\", \"C-3\", \"C-4\", \"I-1\", \"I-2\", \"I-3\", \"I-4\", \"I-5\", \"I-6\", \"Ro-1:\",             \"Ro-7\", \"Ro-9\", \"Ro-10\", \"D-1\", \"D-2\", \"D-3\", \"D-4\", \"D-5\", \"D-6\", \"D-7\", \"D-8\", \"D-9\", \"D-10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    n_embd = 768\n",
    "    n_classes = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bert_classifier(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model_bert = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-uncased')\n",
    "        self.lin = nn.Linear(config.n_embd,config.n_classes)\n",
    "        #self.softmax = nn.softmax()\n",
    "    def forward(self,x):\n",
    "        x = self.model_bert(x)\n",
    "        x = self.lin(x[1])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\vd00r/.cache\\torch\\hub\\huggingface_pytorch-transformers_main\n"
     ]
    }
   ],
   "source": [
    "model = bert_classifier(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_bert.embeddings.word_embeddings.weight\n",
      "model_bert.embeddings.position_embeddings.weight\n",
      "model_bert.embeddings.token_type_embeddings.weight\n",
      "model_bert.embeddings.LayerNorm.weight\n",
      "model_bert.embeddings.LayerNorm.bias\n",
      "model_bert.encoder.layer.0.attention.self.query.weight\n",
      "model_bert.encoder.layer.0.attention.self.query.bias\n",
      "model_bert.encoder.layer.0.attention.self.key.weight\n",
      "model_bert.encoder.layer.0.attention.self.key.bias\n",
      "model_bert.encoder.layer.0.attention.self.value.weight\n",
      "model_bert.encoder.layer.0.attention.self.value.bias\n",
      "model_bert.encoder.layer.0.attention.output.dense.weight\n",
      "model_bert.encoder.layer.0.attention.output.dense.bias\n",
      "model_bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.0.intermediate.dense.weight\n",
      "model_bert.encoder.layer.0.intermediate.dense.bias\n",
      "model_bert.encoder.layer.0.output.dense.weight\n",
      "model_bert.encoder.layer.0.output.dense.bias\n",
      "model_bert.encoder.layer.0.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.0.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.1.attention.self.query.weight\n",
      "model_bert.encoder.layer.1.attention.self.query.bias\n",
      "model_bert.encoder.layer.1.attention.self.key.weight\n",
      "model_bert.encoder.layer.1.attention.self.key.bias\n",
      "model_bert.encoder.layer.1.attention.self.value.weight\n",
      "model_bert.encoder.layer.1.attention.self.value.bias\n",
      "model_bert.encoder.layer.1.attention.output.dense.weight\n",
      "model_bert.encoder.layer.1.attention.output.dense.bias\n",
      "model_bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.1.intermediate.dense.weight\n",
      "model_bert.encoder.layer.1.intermediate.dense.bias\n",
      "model_bert.encoder.layer.1.output.dense.weight\n",
      "model_bert.encoder.layer.1.output.dense.bias\n",
      "model_bert.encoder.layer.1.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.1.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.2.attention.self.query.weight\n",
      "model_bert.encoder.layer.2.attention.self.query.bias\n",
      "model_bert.encoder.layer.2.attention.self.key.weight\n",
      "model_bert.encoder.layer.2.attention.self.key.bias\n",
      "model_bert.encoder.layer.2.attention.self.value.weight\n",
      "model_bert.encoder.layer.2.attention.self.value.bias\n",
      "model_bert.encoder.layer.2.attention.output.dense.weight\n",
      "model_bert.encoder.layer.2.attention.output.dense.bias\n",
      "model_bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.2.intermediate.dense.weight\n",
      "model_bert.encoder.layer.2.intermediate.dense.bias\n",
      "model_bert.encoder.layer.2.output.dense.weight\n",
      "model_bert.encoder.layer.2.output.dense.bias\n",
      "model_bert.encoder.layer.2.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.2.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.3.attention.self.query.weight\n",
      "model_bert.encoder.layer.3.attention.self.query.bias\n",
      "model_bert.encoder.layer.3.attention.self.key.weight\n",
      "model_bert.encoder.layer.3.attention.self.key.bias\n",
      "model_bert.encoder.layer.3.attention.self.value.weight\n",
      "model_bert.encoder.layer.3.attention.self.value.bias\n",
      "model_bert.encoder.layer.3.attention.output.dense.weight\n",
      "model_bert.encoder.layer.3.attention.output.dense.bias\n",
      "model_bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.3.intermediate.dense.weight\n",
      "model_bert.encoder.layer.3.intermediate.dense.bias\n",
      "model_bert.encoder.layer.3.output.dense.weight\n",
      "model_bert.encoder.layer.3.output.dense.bias\n",
      "model_bert.encoder.layer.3.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.3.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.4.attention.self.query.weight\n",
      "model_bert.encoder.layer.4.attention.self.query.bias\n",
      "model_bert.encoder.layer.4.attention.self.key.weight\n",
      "model_bert.encoder.layer.4.attention.self.key.bias\n",
      "model_bert.encoder.layer.4.attention.self.value.weight\n",
      "model_bert.encoder.layer.4.attention.self.value.bias\n",
      "model_bert.encoder.layer.4.attention.output.dense.weight\n",
      "model_bert.encoder.layer.4.attention.output.dense.bias\n",
      "model_bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.4.intermediate.dense.weight\n",
      "model_bert.encoder.layer.4.intermediate.dense.bias\n",
      "model_bert.encoder.layer.4.output.dense.weight\n",
      "model_bert.encoder.layer.4.output.dense.bias\n",
      "model_bert.encoder.layer.4.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.4.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.5.attention.self.query.weight\n",
      "model_bert.encoder.layer.5.attention.self.query.bias\n",
      "model_bert.encoder.layer.5.attention.self.key.weight\n",
      "model_bert.encoder.layer.5.attention.self.key.bias\n",
      "model_bert.encoder.layer.5.attention.self.value.weight\n",
      "model_bert.encoder.layer.5.attention.self.value.bias\n",
      "model_bert.encoder.layer.5.attention.output.dense.weight\n",
      "model_bert.encoder.layer.5.attention.output.dense.bias\n",
      "model_bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.5.intermediate.dense.weight\n",
      "model_bert.encoder.layer.5.intermediate.dense.bias\n",
      "model_bert.encoder.layer.5.output.dense.weight\n",
      "model_bert.encoder.layer.5.output.dense.bias\n",
      "model_bert.encoder.layer.5.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.5.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.6.attention.self.query.weight\n",
      "model_bert.encoder.layer.6.attention.self.query.bias\n",
      "model_bert.encoder.layer.6.attention.self.key.weight\n",
      "model_bert.encoder.layer.6.attention.self.key.bias\n",
      "model_bert.encoder.layer.6.attention.self.value.weight\n",
      "model_bert.encoder.layer.6.attention.self.value.bias\n",
      "model_bert.encoder.layer.6.attention.output.dense.weight\n",
      "model_bert.encoder.layer.6.attention.output.dense.bias\n",
      "model_bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.6.intermediate.dense.weight\n",
      "model_bert.encoder.layer.6.intermediate.dense.bias\n",
      "model_bert.encoder.layer.6.output.dense.weight\n",
      "model_bert.encoder.layer.6.output.dense.bias\n",
      "model_bert.encoder.layer.6.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.6.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.7.attention.self.query.weight\n",
      "model_bert.encoder.layer.7.attention.self.query.bias\n",
      "model_bert.encoder.layer.7.attention.self.key.weight\n",
      "model_bert.encoder.layer.7.attention.self.key.bias\n",
      "model_bert.encoder.layer.7.attention.self.value.weight\n",
      "model_bert.encoder.layer.7.attention.self.value.bias\n",
      "model_bert.encoder.layer.7.attention.output.dense.weight\n",
      "model_bert.encoder.layer.7.attention.output.dense.bias\n",
      "model_bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.7.intermediate.dense.weight\n",
      "model_bert.encoder.layer.7.intermediate.dense.bias\n",
      "model_bert.encoder.layer.7.output.dense.weight\n",
      "model_bert.encoder.layer.7.output.dense.bias\n",
      "model_bert.encoder.layer.7.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.7.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.8.attention.self.query.weight\n",
      "model_bert.encoder.layer.8.attention.self.query.bias\n",
      "model_bert.encoder.layer.8.attention.self.key.weight\n",
      "model_bert.encoder.layer.8.attention.self.key.bias\n",
      "model_bert.encoder.layer.8.attention.self.value.weight\n",
      "model_bert.encoder.layer.8.attention.self.value.bias\n",
      "model_bert.encoder.layer.8.attention.output.dense.weight\n",
      "model_bert.encoder.layer.8.attention.output.dense.bias\n",
      "model_bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.8.intermediate.dense.weight\n",
      "model_bert.encoder.layer.8.intermediate.dense.bias\n",
      "model_bert.encoder.layer.8.output.dense.weight\n",
      "model_bert.encoder.layer.8.output.dense.bias\n",
      "model_bert.encoder.layer.8.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.8.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.9.attention.self.query.weight\n",
      "model_bert.encoder.layer.9.attention.self.query.bias\n",
      "model_bert.encoder.layer.9.attention.self.key.weight\n",
      "model_bert.encoder.layer.9.attention.self.key.bias\n",
      "model_bert.encoder.layer.9.attention.self.value.weight\n",
      "model_bert.encoder.layer.9.attention.self.value.bias\n",
      "model_bert.encoder.layer.9.attention.output.dense.weight\n",
      "model_bert.encoder.layer.9.attention.output.dense.bias\n",
      "model_bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.9.intermediate.dense.weight\n",
      "model_bert.encoder.layer.9.intermediate.dense.bias\n",
      "model_bert.encoder.layer.9.output.dense.weight\n",
      "model_bert.encoder.layer.9.output.dense.bias\n",
      "model_bert.encoder.layer.9.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.9.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.10.attention.self.query.weight\n",
      "model_bert.encoder.layer.10.attention.self.query.bias\n",
      "model_bert.encoder.layer.10.attention.self.key.weight\n",
      "model_bert.encoder.layer.10.attention.self.key.bias\n",
      "model_bert.encoder.layer.10.attention.self.value.weight\n",
      "model_bert.encoder.layer.10.attention.self.value.bias\n",
      "model_bert.encoder.layer.10.attention.output.dense.weight\n",
      "model_bert.encoder.layer.10.attention.output.dense.bias\n",
      "model_bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.10.intermediate.dense.weight\n",
      "model_bert.encoder.layer.10.intermediate.dense.bias\n",
      "model_bert.encoder.layer.10.output.dense.weight\n",
      "model_bert.encoder.layer.10.output.dense.bias\n",
      "model_bert.encoder.layer.10.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.10.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.11.attention.self.query.weight\n",
      "model_bert.encoder.layer.11.attention.self.query.bias\n",
      "model_bert.encoder.layer.11.attention.self.key.weight\n",
      "model_bert.encoder.layer.11.attention.self.key.bias\n",
      "model_bert.encoder.layer.11.attention.self.value.weight\n",
      "model_bert.encoder.layer.11.attention.self.value.bias\n",
      "model_bert.encoder.layer.11.attention.output.dense.weight\n",
      "model_bert.encoder.layer.11.attention.output.dense.bias\n",
      "model_bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "model_bert.encoder.layer.11.intermediate.dense.weight\n",
      "model_bert.encoder.layer.11.intermediate.dense.bias\n",
      "model_bert.encoder.layer.11.output.dense.weight\n",
      "model_bert.encoder.layer.11.output.dense.bias\n",
      "model_bert.encoder.layer.11.output.LayerNorm.weight\n",
      "model_bert.encoder.layer.11.output.LayerNorm.bias\n",
      "model_bert.pooler.dense.weight\n",
      "model_bert.pooler.dense.bias\n",
      "lin.weight\n",
      "lin.bias\n"
     ]
    }
   ],
   "source": [
    "for param in model.named_parameters():\n",
    "    print(param[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lin.bias', 'lin.weight', 'model_bert.pooler.dense.bias', 'model_bert.pooler.dense.weight', 'model_bert.encoder.layer.11.output.LayerNorm.bias', 'model_bert.encoder.layer.11.output.LayerNorm.weight', 'model_bert.encoder.layer.11.output.dense.bias', 'model_bert.encoder.layer.11.output.dense.weight', 'model_bert.encoder.layer.11.intermediate.dense.bias', 'model_bert.encoder.layer.11.intermediate.dense.weight', 'model_bert.encoder.layer.11.attention.output.LayerNorm.bias', 'model_bert.encoder.layer.11.attention.output.LayerNorm.weight', 'model_bert.encoder.layer.11.attention.output.dense.bias', 'model_bert.encoder.layer.11.attention.output.dense.weight', 'model_bert.encoder.layer.11.attention.self.value.bias', 'model_bert.encoder.layer.11.attention.self.value.weight', 'model_bert.encoder.layer.11.attention.self.key.bias', 'model_bert.encoder.layer.11.attention.self.key.weight', 'model_bert.encoder.layer.11.attention.self.query.bias', 'model_bert.encoder.layer.11.attention.self.query.weight', 'model_bert.encoder.layer.10.output.LayerNorm.bias', 'model_bert.encoder.layer.10.output.LayerNorm.weight', 'model_bert.encoder.layer.10.output.dense.bias', 'model_bert.encoder.layer.10.output.dense.weight', 'model_bert.encoder.layer.10.intermediate.dense.bias', 'model_bert.encoder.layer.10.intermediate.dense.weight', 'model_bert.encoder.layer.10.attention.output.LayerNorm.bias', 'model_bert.encoder.layer.10.attention.output.LayerNorm.weight', 'model_bert.encoder.layer.10.attention.output.dense.bias', 'model_bert.encoder.layer.10.attention.output.dense.weight', 'model_bert.encoder.layer.10.attention.self.value.bias', 'model_bert.encoder.layer.10.attention.self.value.weight', 'model_bert.encoder.layer.10.attention.self.key.bias', 'model_bert.encoder.layer.10.attention.self.key.weight', 'model_bert.encoder.layer.10.attention.self.query.bias', 'model_bert.encoder.layer.10.attention.self.query.weight', 'model_bert.encoder.layer.9.output.LayerNorm.bias', 'model_bert.encoder.layer.9.output.LayerNorm.weight', 'model_bert.encoder.layer.9.output.dense.bias', 'model_bert.encoder.layer.9.output.dense.weight', 'model_bert.encoder.layer.9.intermediate.dense.bias', 'model_bert.encoder.layer.9.intermediate.dense.weight', 'model_bert.encoder.layer.9.attention.output.LayerNorm.bias', 'model_bert.encoder.layer.9.attention.output.LayerNorm.weight', 'model_bert.encoder.layer.9.attention.output.dense.bias', 'model_bert.encoder.layer.9.attention.output.dense.weight', 'model_bert.encoder.layer.9.attention.self.value.bias', 'model_bert.encoder.layer.9.attention.self.value.weight', 'model_bert.encoder.layer.9.attention.self.key.bias', 'model_bert.encoder.layer.9.attention.self.key.weight', 'model_bert.encoder.layer.9.attention.self.query.bias', 'model_bert.encoder.layer.9.attention.self.query.weight', 'model_bert.encoder.layer.8.output.LayerNorm.bias', 'model_bert.encoder.layer.8.output.LayerNorm.weight', 'model_bert.encoder.layer.8.output.dense.bias', 'model_bert.encoder.layer.8.output.dense.weight', 'model_bert.encoder.layer.8.intermediate.dense.bias', 'model_bert.encoder.layer.8.intermediate.dense.weight', 'model_bert.encoder.layer.8.attention.output.LayerNorm.bias', 'model_bert.encoder.layer.8.attention.output.LayerNorm.weight', 'model_bert.encoder.layer.8.attention.output.dense.bias', 'model_bert.encoder.layer.8.attention.output.dense.weight', 'model_bert.encoder.layer.8.attention.self.value.bias', 'model_bert.encoder.layer.8.attention.self.value.weight', 'model_bert.encoder.layer.8.attention.self.key.bias', 'model_bert.encoder.layer.8.attention.self.key.weight', 'model_bert.encoder.layer.8.attention.self.query.bias', 'model_bert.encoder.layer.8.attention.self.query.weight', 'model_bert.encoder.layer.7.output.LayerNorm.bias', 'model_bert.encoder.layer.7.output.LayerNorm.weight', 'model_bert.encoder.layer.7.output.dense.bias', 'model_bert.encoder.layer.7.output.dense.weight', 'model_bert.encoder.layer.7.intermediate.dense.bias', 'model_bert.encoder.layer.7.intermediate.dense.weight', 'model_bert.encoder.layer.7.attention.output.LayerNorm.bias', 'model_bert.encoder.layer.7.attention.output.LayerNorm.weight', 'model_bert.encoder.layer.7.attention.output.dense.bias', 'model_bert.encoder.layer.7.attention.output.dense.weight', 'model_bert.encoder.layer.7.attention.self.value.bias', 'model_bert.encoder.layer.7.attention.self.value.weight', 'model_bert.encoder.layer.7.attention.self.key.bias', 'model_bert.encoder.layer.7.attention.self.key.weight', 'model_bert.encoder.layer.7.attention.self.query.bias', 'model_bert.encoder.layer.7.attention.self.query.weight', 'model_bert.encoder.layer.6.output.LayerNorm.bias', 'model_bert.encoder.layer.6.output.LayerNorm.weight', 'model_bert.encoder.layer.6.output.dense.bias', 'model_bert.encoder.layer.6.output.dense.weight', 'model_bert.encoder.layer.6.intermediate.dense.bias', 'model_bert.encoder.layer.6.intermediate.dense.weight', 'model_bert.encoder.layer.6.attention.output.LayerNorm.bias', 'model_bert.encoder.layer.6.attention.output.LayerNorm.weight', 'model_bert.encoder.layer.6.attention.output.dense.bias', 'model_bert.encoder.layer.6.attention.output.dense.weight', 'model_bert.encoder.layer.6.attention.self.value.bias', 'model_bert.encoder.layer.6.attention.self.value.weight', 'model_bert.encoder.layer.6.attention.self.key.bias', 'model_bert.encoder.layer.6.attention.self.key.weight', 'model_bert.encoder.layer.6.attention.self.query.bias', 'model_bert.encoder.layer.6.attention.self.query.weight', 'model_bert.encoder.layer.5.output.LayerNorm.bias', 'model_bert.encoder.layer.5.output.LayerNorm.weight', 'model_bert.encoder.layer.5.output.dense.bias', 'model_bert.encoder.layer.5.output.dense.weight', 'model_bert.encoder.layer.5.intermediate.dense.bias', 'model_bert.encoder.layer.5.intermediate.dense.weight', 'model_bert.encoder.layer.5.attention.output.LayerNorm.bias', 'model_bert.encoder.layer.5.attention.output.LayerNorm.weight', 'model_bert.encoder.layer.5.attention.output.dense.bias', 'model_bert.encoder.layer.5.attention.output.dense.weight', 'model_bert.encoder.layer.5.attention.self.value.bias', 'model_bert.encoder.layer.5.attention.self.value.weight', 'model_bert.encoder.layer.5.attention.self.key.bias', 'model_bert.encoder.layer.5.attention.self.key.weight', 'model_bert.encoder.layer.5.attention.self.query.bias', 'model_bert.encoder.layer.5.attention.self.query.weight', 'model_bert.encoder.layer.4.output.LayerNorm.bias', 'model_bert.encoder.layer.4.output.LayerNorm.weight', 'model_bert.encoder.layer.4.output.dense.bias', 'model_bert.encoder.layer.4.output.dense.weight', 'model_bert.encoder.layer.4.intermediate.dense.bias', 'model_bert.encoder.layer.4.intermediate.dense.weight', 'model_bert.encoder.layer.4.attention.output.LayerNorm.bias', 'model_bert.encoder.layer.4.attention.output.LayerNorm.weight', 'model_bert.encoder.layer.4.attention.output.dense.bias', 'model_bert.encoder.layer.4.attention.output.dense.weight', 'model_bert.encoder.layer.4.attention.self.value.bias', 'model_bert.encoder.layer.4.attention.self.value.weight', 'model_bert.encoder.layer.4.attention.self.key.bias', 'model_bert.encoder.layer.4.attention.self.key.weight', 'model_bert.encoder.layer.4.attention.self.query.bias', 'model_bert.encoder.layer.4.attention.self.query.weight', 'model_bert.encoder.layer.3.output.LayerNorm.bias', 'model_bert.encoder.layer.3.output.LayerNorm.weight', 'model_bert.encoder.layer.3.output.dense.bias', 'model_bert.encoder.layer.3.output.dense.weight', 'model_bert.encoder.layer.3.intermediate.dense.bias', 'model_bert.encoder.layer.3.intermediate.dense.weight', 'model_bert.encoder.layer.3.attention.output.LayerNorm.bias', 'model_bert.encoder.layer.3.attention.output.LayerNorm.weight', 'model_bert.encoder.layer.3.attention.output.dense.bias', 'model_bert.encoder.layer.3.attention.output.dense.weight', 'model_bert.encoder.layer.3.attention.self.value.bias', 'model_bert.encoder.layer.3.attention.self.value.weight', 'model_bert.encoder.layer.3.attention.self.key.bias', 'model_bert.encoder.layer.3.attention.self.key.weight', 'model_bert.encoder.layer.3.attention.self.query.bias', 'model_bert.encoder.layer.3.attention.self.query.weight', 'model_bert.encoder.layer.2.output.LayerNorm.bias', 'model_bert.encoder.layer.2.output.LayerNorm.weight', 'model_bert.encoder.layer.2.output.dense.bias', 'model_bert.encoder.layer.2.output.dense.weight', 'model_bert.encoder.layer.2.intermediate.dense.bias', 'model_bert.encoder.layer.2.intermediate.dense.weight', 'model_bert.encoder.layer.2.attention.output.LayerNorm.bias', 'model_bert.encoder.layer.2.attention.output.LayerNorm.weight', 'model_bert.encoder.layer.2.attention.output.dense.bias', 'model_bert.encoder.layer.2.attention.output.dense.weight', 'model_bert.encoder.layer.2.attention.self.value.bias', 'model_bert.encoder.layer.2.attention.self.value.weight', 'model_bert.encoder.layer.2.attention.self.key.bias', 'model_bert.encoder.layer.2.attention.self.key.weight', 'model_bert.encoder.layer.2.attention.self.query.bias', 'model_bert.encoder.layer.2.attention.self.query.weight', 'model_bert.encoder.layer.1.output.LayerNorm.bias', 'model_bert.encoder.layer.1.output.LayerNorm.weight', 'model_bert.encoder.layer.1.output.dense.bias', 'model_bert.encoder.layer.1.output.dense.weight', 'model_bert.encoder.layer.1.intermediate.dense.bias', 'model_bert.encoder.layer.1.intermediate.dense.weight', 'model_bert.encoder.layer.1.attention.output.LayerNorm.bias', 'model_bert.encoder.layer.1.attention.output.LayerNorm.weight', 'model_bert.encoder.layer.1.attention.output.dense.bias', 'model_bert.encoder.layer.1.attention.output.dense.weight', 'model_bert.encoder.layer.1.attention.self.value.bias', 'model_bert.encoder.layer.1.attention.self.value.weight', 'model_bert.encoder.layer.1.attention.self.key.bias', 'model_bert.encoder.layer.1.attention.self.key.weight', 'model_bert.encoder.layer.1.attention.self.query.bias', 'model_bert.encoder.layer.1.attention.self.query.weight', 'model_bert.encoder.layer.0.output.LayerNorm.bias', 'model_bert.encoder.layer.0.output.LayerNorm.weight', 'model_bert.encoder.layer.0.output.dense.bias', 'model_bert.encoder.layer.0.output.dense.weight', 'model_bert.encoder.layer.0.intermediate.dense.bias', 'model_bert.encoder.layer.0.intermediate.dense.weight', 'model_bert.encoder.layer.0.attention.output.LayerNorm.bias', 'model_bert.encoder.layer.0.attention.output.LayerNorm.weight', 'model_bert.encoder.layer.0.attention.output.dense.bias', 'model_bert.encoder.layer.0.attention.output.dense.weight', 'model_bert.encoder.layer.0.attention.self.value.bias', 'model_bert.encoder.layer.0.attention.self.value.weight', 'model_bert.encoder.layer.0.attention.self.key.bias', 'model_bert.encoder.layer.0.attention.self.key.weight', 'model_bert.encoder.layer.0.attention.self.query.bias', 'model_bert.encoder.layer.0.attention.self.query.weight', 'model_bert.embeddings.LayerNorm.bias', 'model_bert.embeddings.LayerNorm.weight', 'model_bert.embeddings.token_type_embeddings.weight', 'model_bert.embeddings.position_embeddings.weight', 'model_bert.embeddings.word_embeddings.weight']\n"
     ]
    }
   ],
   "source": [
    "#for name, layer in model_bert.encoder.named_children():\n",
    "        #print(layer)\n",
    "layer_names = []\n",
    "for param in model.named_parameters():\n",
    "     layer_names.append(param[0])\n",
    "layer_names.reverse()\n",
    "print(layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "bert_classifier                                              [1, 32]                   --\n",
       "├─BertModel: 1-1                                             [1, 768]                  --\n",
       "│    └─BertEmbeddings: 2-1                                   [1, 512, 768]             --\n",
       "│    │    └─Embedding: 3-1                                   [1, 512, 768]             23,440,896\n",
       "│    │    └─Embedding: 3-2                                   [1, 512, 768]             1,536\n",
       "│    │    └─Embedding: 3-3                                   [1, 512, 768]             393,216\n",
       "│    │    └─LayerNorm: 3-4                                   [1, 512, 768]             1,536\n",
       "│    │    └─Dropout: 3-5                                     [1, 512, 768]             --\n",
       "│    └─BertEncoder: 2-2                                      [1, 512, 768]             --\n",
       "│    │    └─ModuleList: 3-6                                  --                        85,054,464\n",
       "│    └─BertPooler: 2-3                                       [1, 768]                  --\n",
       "│    │    └─Linear: 3-7                                      [1, 768]                  590,592\n",
       "│    │    └─Tanh: 3-8                                        [1, 768]                  --\n",
       "├─Linear: 1-2                                                [1, 32]                   24,608\n",
       "==============================================================================================================\n",
       "Total params: 109,506,848\n",
       "Trainable params: 109,506,848\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 109.51\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 427.83\n",
       "Params size (MB): 438.03\n",
       "Estimated Total Size (MB): 865.85\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model,input_data=torch.ones([1,512],dtype=torch.int32).to(device))\n",
    "#print(model(torch.ones([1,512],dtype=torch.int32)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (2267807764.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[264], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    tokenizer = BertTokenizer(#vocab_file)\u001b[0m\n\u001b[1;37m                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer(#vocab_file)\n",
    "input = \"They shot at him, but they aimed at all of us. The assasination attempt on President Donald J. Trump yesterday was not just an isolated event. It was the culmination of years of attacks being leveled at the President, and all Republicans. We are in a battle for the soul of our Nation. This is not simply about who will be President, but what course our country will take for generations to come. They’ve indicted him, attacked him, impeached him and shot him. He’s still standing. And we need to stand with him. Every election this year is important. In August, and November, we need leaders in office who will FIGHT for our state and nation. I continue to pray for the families of those who lost loved ones yesterday, and for the Trump family, but I’m ready to get out and fight for our country and vote for our future in the coming elections. Will you join me?\"\n",
    "tok = tokenizer.encode_plus(input)\n",
    "print(len(tok[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----TRAINING-HYPERPARAMETERS-----#\n",
    "max_lr = 1#3e-4\n",
    "min_lr = max_lr * 0.01\n",
    "warmup_steps = 100\n",
    "max_steps = 3000\n",
    "theta = 0.9\n",
    "#-----TRAINING-HYPERPARAMETERS-----#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----BATCH-SIZE/GRADIENT-ACCUMILATION-----#\n",
    "batch_size = 1024\n",
    "B = 4\n",
    "grad_accum_steps = batch_size // B\n",
    "loader = dataloader(B = B)\n",
    "val_loader = dataloader(B = B, split=\"val\")\n",
    "print(grad_accum_steps)\n",
    "#-----BATCH-SIZE/GRADIENT-ACCUMILATION-----#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----LEARNING-RATE-SCHEDULER-----#\n",
    "def get_lr(it):\n",
    "    if it < warmup_steps:\n",
    "        return max_lr * (it+1) / warmup_steps\n",
    "    if it > max_steps:\n",
    "        return min_lr\n",
    "    decay = it-warmup_steps\n",
    "    return max_lr - decay * (max_lr/(max_steps-warmup_steps))\n",
    "#-----LEARNING-RATE-SCHEDULER-----#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "     param.requires_grad = False\n",
    "for param in model.model_bert.pooler.parameters():\n",
    "     param.requires_grad = True\n",
    "for param in model.lin.parameters():\n",
    "     param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----GRADUAL-FREEZING----#\n",
    "class gradual_freezing():\n",
    "    def __init__(self):\n",
    "        self.unlock_ratio = 0.083\n",
    "        self.i = 12\n",
    "    def check_unfreeze(self,it):\n",
    "        ratio = it/max_steps\n",
    "        #print(ratio)\n",
    "        #print(self.unlock_ratio)\n",
    "        if ratio > self.unlock_ratio and self.i != 0:\n",
    "            self.unlock_ratio = self.unlock_ratio +  0.083\n",
    "            self.i = self.i - 1\n",
    "            print(self.i)\n",
    "            for param in model.model_bert.encoder.layer[self.i].parameters():\n",
    "                param.requires_grad = True\n",
    "                #print(param[0])\n",
    "            return True\n",
    "        return False\n",
    "#-----GRADUAL-FREEZING-----#\n",
    "#a = gradual_freezing()\n",
    "#for g in range(2000):\n",
    "    #a.check_unfreeze(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'params': Parameter containing:\n",
      "tensor([ 0.0124, -0.0055,  0.0181,  0.0077,  0.0319,  0.0086,  0.0003, -0.0271,\n",
      "         0.0104, -0.0144,  0.0065,  0.0318,  0.0106,  0.0336,  0.0097, -0.0029,\n",
      "         0.0127, -0.0134,  0.0276, -0.0213, -0.0202, -0.0026,  0.0145,  0.0283,\n",
      "         0.0065,  0.0337, -0.0233,  0.0121,  0.0277,  0.0320, -0.0238, -0.0233],\n",
      "       device='cuda:0', requires_grad=True), 'lr': 1}, {'params': Parameter containing:\n",
      "tensor([[-0.0314, -0.0241,  0.0150,  ...,  0.0191, -0.0291,  0.0134],\n",
      "        [-0.0059,  0.0165, -0.0024,  ..., -0.0281, -0.0257, -0.0268],\n",
      "        [ 0.0043,  0.0048,  0.0176,  ..., -0.0028,  0.0354, -0.0021],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0286, -0.0064,  ...,  0.0352,  0.0002,  0.0291],\n",
      "        [ 0.0051,  0.0347,  0.0124,  ...,  0.0214, -0.0196,  0.0236],\n",
      "        [ 0.0038, -0.0122, -0.0261,  ...,  0.0347,  0.0233,  0.0263]],\n",
      "       device='cuda:0', requires_grad=True), 'lr': 1}, {'params': Parameter containing:\n",
      "tensor([-3.5976e-02, -3.8954e-03,  5.1814e-02,  2.2247e-02, -4.9372e-03,\n",
      "        -1.1203e-03,  2.6339e-02,  9.0639e-03,  3.8723e-02, -9.6557e-02,\n",
      "         2.3311e-02, -2.0086e-02,  6.5490e-02, -5.1680e-02,  6.6156e-02,\n",
      "        -1.4721e-02, -4.5325e-03, -8.4059e-04,  1.3027e-02, -2.9770e-02,\n",
      "         4.3693e-02, -1.4292e-02,  4.5489e-02,  4.5346e-03,  7.6859e-03,\n",
      "        -4.0926e-02, -1.1412e-02,  6.6037e-02,  6.7376e-02,  4.2859e-02,\n",
      "        -2.6975e-02,  3.5281e-05, -8.1483e-02, -3.7569e-03,  4.0570e-02,\n",
      "        -5.7694e-02, -8.3285e-03, -2.6218e-02, -4.7924e-03, -8.2249e-03,\n",
      "        -6.4672e-02,  1.9579e-03,  7.2015e-02, -2.2552e-02,  3.4110e-03,\n",
      "        -1.4251e-02, -8.3488e-03,  3.8957e-03, -5.5111e-02, -4.8916e-02,\n",
      "        -4.0505e-02, -3.5423e-02,  6.1806e-03,  9.7887e-04,  2.5234e-03,\n",
      "         3.8691e-03, -7.2486e-03, -2.1082e-03,  1.9743e-03, -1.5894e-02,\n",
      "        -1.4470e-02,  3.2000e-03,  2.3056e-02, -4.6876e-02, -3.6722e-02,\n",
      "        -7.3898e-02, -4.4587e-03,  5.0023e-03,  6.9043e-03,  3.3589e-03,\n",
      "         2.2775e-02, -3.1106e-03,  2.4767e-02, -4.8293e-02, -5.0632e-02,\n",
      "         3.7559e-03, -8.8531e-03,  1.7421e-02, -5.2642e-03, -7.4719e-02,\n",
      "        -3.0047e-02, -5.3653e-02,  8.8173e-03,  6.1905e-02, -6.8883e-02,\n",
      "        -2.1225e-02, -8.6340e-03, -1.7548e-03, -8.5851e-02,  5.9378e-03,\n",
      "         1.1967e-02,  2.0897e-03, -4.2413e-02,  8.7467e-03,  4.5203e-02,\n",
      "        -7.6098e-03,  1.8549e-04,  2.8614e-02,  2.0781e-03, -4.9508e-03,\n",
      "        -8.8196e-03, -3.4198e-03,  7.3986e-03, -1.7159e-03,  3.8593e-03,\n",
      "        -9.6255e-03, -1.3085e-02, -1.6207e-02, -4.1687e-02,  9.7658e-03,\n",
      "         8.9834e-03, -5.8610e-03, -1.4935e-03, -5.3537e-02,  5.5583e-03,\n",
      "        -1.0870e-04, -8.4393e-02, -2.0534e-02, -8.6620e-02,  3.6078e-02,\n",
      "         5.2120e-03, -1.4668e-02,  6.6004e-02,  3.5172e-02,  4.0267e-03,\n",
      "        -3.8512e-03,  4.1188e-02, -9.5374e-03,  8.4221e-03,  4.1511e-03,\n",
      "         3.0034e-02, -6.3468e-04, -7.1196e-02, -7.6416e-02,  1.1497e-02,\n",
      "         6.4726e-02,  2.7181e-03,  6.8666e-02, -4.0454e-03,  5.6817e-02,\n",
      "         4.0652e-02,  1.6854e-02, -3.1005e-02, -1.3064e-02,  2.8483e-03,\n",
      "         1.6498e-02, -3.0347e-02,  8.9853e-03, -7.7755e-03, -1.8113e-02,\n",
      "        -2.2885e-03, -5.0442e-03,  4.7131e-02, -6.0013e-02, -8.7461e-03,\n",
      "         5.9925e-02,  2.1879e-02,  6.8031e-02,  6.3506e-02, -4.2697e-03,\n",
      "        -1.4504e-02,  4.1974e-02,  9.1194e-03,  3.0824e-03,  2.6392e-02,\n",
      "         1.1135e-04, -6.1943e-02,  5.2578e-03, -3.5484e-02,  1.7566e-02,\n",
      "         3.5716e-03, -4.5841e-03,  4.8374e-02, -7.5280e-02, -4.6712e-03,\n",
      "         1.6970e-02,  8.2794e-02,  4.9445e-02,  4.4020e-03, -2.7126e-02,\n",
      "        -1.0707e-02, -2.4882e-02, -6.9837e-02,  7.4775e-02,  6.0947e-03,\n",
      "         1.8029e-03,  6.6490e-03, -1.5068e-02, -4.7108e-02, -4.8279e-02,\n",
      "         2.2051e-02,  1.0339e-02, -4.7205e-02, -4.5817e-03, -9.0287e-03,\n",
      "        -2.7196e-03,  3.0730e-03,  3.3383e-02,  5.3510e-03, -1.1000e-02,\n",
      "        -4.3553e-03,  6.9025e-02,  2.8795e-02,  3.3619e-02, -1.4701e-02,\n",
      "         1.4060e-02, -4.8320e-02, -3.1883e-02, -1.4480e-03,  6.0081e-03,\n",
      "         2.3593e-03,  8.4787e-02,  1.2406e-02,  2.5789e-03, -5.0564e-02,\n",
      "        -8.2032e-02, -9.4141e-04, -5.5241e-02, -7.6775e-03, -2.4861e-02,\n",
      "         9.4571e-03,  5.8841e-03, -4.7154e-02,  3.5717e-03, -4.3507e-02,\n",
      "        -4.6676e-02, -1.2599e-03, -8.0774e-03,  2.4329e-03, -7.5354e-03,\n",
      "         1.5403e-02, -3.6249e-02, -2.7785e-02,  2.7119e-02,  6.7980e-02,\n",
      "         3.1430e-02, -5.2584e-02,  3.7485e-02, -4.8816e-03,  3.0093e-02,\n",
      "        -1.1456e-02,  5.6422e-02, -1.2345e-02,  6.0983e-03, -6.2267e-02,\n",
      "         4.3605e-02, -3.8197e-02,  5.2499e-02,  1.6630e-04, -7.5969e-02,\n",
      "        -6.4865e-02,  1.3884e-02, -1.3189e-03,  6.7656e-02, -9.5227e-03,\n",
      "         3.3197e-02, -2.3533e-02, -7.0145e-02, -1.0432e-02,  2.8274e-02,\n",
      "        -8.1062e-02, -3.1947e-02, -2.7126e-03, -1.3334e-02, -2.8135e-03,\n",
      "        -1.0706e-02, -6.9299e-02,  3.4644e-02, -2.9170e-03,  4.5919e-02,\n",
      "        -8.9445e-03, -2.6880e-02,  1.2639e-02, -6.7561e-02, -7.4783e-04,\n",
      "         6.1452e-03,  5.0698e-02, -8.5238e-03, -5.8640e-02,  1.7157e-03,\n",
      "         2.5632e-02,  1.0620e-02,  5.4907e-02,  3.9250e-02,  1.3627e-02,\n",
      "         7.0662e-02,  5.1439e-02,  3.4894e-02,  1.0701e-02, -1.6566e-02,\n",
      "         1.0428e-01,  3.2651e-02, -1.1483e-02, -6.2328e-02, -1.2810e-02,\n",
      "         3.5336e-02, -1.5002e-02, -1.1252e-02,  1.3703e-04, -5.9601e-02,\n",
      "        -4.1940e-02,  6.4488e-02,  3.5795e-02, -1.1073e-02,  4.2960e-02,\n",
      "         6.6363e-02, -2.1350e-02, -2.8048e-02, -7.8367e-03,  5.9328e-02,\n",
      "        -1.1968e-02,  1.9762e-02,  1.6436e-03, -1.9586e-04,  4.5457e-02,\n",
      "        -3.3673e-02,  2.8175e-02,  3.0951e-02, -8.4503e-03,  4.3550e-03,\n",
      "        -1.8311e-02, -6.0869e-02,  7.6723e-03, -8.1489e-03, -2.4181e-02,\n",
      "        -6.5763e-02, -3.1222e-03, -2.7059e-02,  5.2479e-03,  2.2024e-03,\n",
      "         2.2695e-03, -3.7777e-02,  2.9974e-05, -5.2179e-02,  8.6420e-03,\n",
      "         1.5367e-02, -2.6896e-02, -2.3252e-02,  1.3346e-02, -2.8418e-02,\n",
      "         5.2154e-02, -6.8118e-02,  6.3350e-02, -2.9627e-03, -3.7981e-02,\n",
      "         2.4390e-02, -2.4529e-03, -5.2262e-02,  4.4196e-03,  4.0819e-03,\n",
      "        -5.2573e-04,  1.5752e-02, -4.7064e-03, -7.4060e-02, -1.7793e-02,\n",
      "        -1.8469e-02,  4.7606e-03, -4.6088e-03,  7.6716e-02, -1.5433e-04,\n",
      "         3.2812e-02,  9.1863e-03,  7.8530e-02, -7.5982e-02, -3.3673e-02,\n",
      "        -4.5526e-02, -7.1196e-02,  6.6536e-02,  6.6131e-02,  3.4918e-03,\n",
      "        -4.2715e-02, -7.3834e-04,  5.9887e-02, -9.4803e-03, -5.1243e-02,\n",
      "         4.2864e-03,  2.6319e-02, -9.7941e-03,  5.9664e-02, -2.4174e-02,\n",
      "        -1.1204e-02, -7.2384e-03,  4.9288e-03,  1.6533e-02, -2.4369e-02,\n",
      "         6.4933e-03, -1.3649e-02, -2.4182e-03, -6.2799e-03, -1.7210e-02,\n",
      "        -7.2431e-02, -7.8740e-03,  1.2792e-02,  2.0920e-02, -1.2329e-02,\n",
      "         3.8972e-02, -7.1581e-03, -1.2284e-02,  1.9917e-03,  7.4051e-03,\n",
      "        -1.4321e-02, -3.5394e-02, -2.4015e-02, -3.2418e-02, -7.5521e-02,\n",
      "         3.2948e-02,  1.5901e-03, -2.8555e-03,  2.7893e-03, -3.4312e-03,\n",
      "         2.5345e-03, -1.6758e-02, -4.9462e-02,  3.2866e-03,  1.2931e-02,\n",
      "        -5.2172e-02,  7.3928e-02, -4.0985e-03,  9.5864e-03,  3.0872e-02,\n",
      "         5.2427e-02, -1.4434e-02, -2.9415e-03, -4.2015e-03, -6.0903e-02,\n",
      "         5.1717e-03, -6.3032e-02,  6.9126e-02, -3.7929e-02,  7.9866e-03,\n",
      "         6.0435e-03, -8.5405e-03,  1.0294e-02, -9.4331e-03,  2.0938e-02,\n",
      "        -8.2480e-03,  3.0896e-02,  1.7897e-02, -2.8527e-02, -1.5033e-02,\n",
      "         3.5082e-03,  5.9243e-02, -3.4988e-03, -1.2596e-03, -6.2648e-02,\n",
      "        -5.5414e-02, -1.9697e-02, -4.5624e-02, -7.3769e-02,  3.9488e-02,\n",
      "         2.1077e-02,  7.9621e-03,  8.1903e-03, -6.0914e-03, -1.0476e-02,\n",
      "        -2.5105e-02, -4.3828e-03, -6.4321e-02,  4.9943e-02, -1.9390e-02,\n",
      "         1.1147e-02, -4.4764e-03,  6.2568e-03, -6.4056e-02,  7.2374e-02,\n",
      "         1.0556e-02,  1.0156e-03,  7.9476e-03, -2.9068e-02,  1.5874e-02,\n",
      "        -2.6810e-02,  2.9566e-02, -5.4999e-03,  1.3515e-02, -1.0681e-02,\n",
      "        -5.0631e-02,  4.0818e-02,  2.0823e-02,  3.9909e-03,  7.8542e-03,\n",
      "        -4.6300e-02,  2.4748e-03,  6.9978e-02,  4.5245e-02, -1.6835e-02,\n",
      "        -1.0396e-02,  1.5637e-02, -5.6454e-03, -7.2900e-02,  5.3020e-02,\n",
      "         1.3894e-02, -1.8712e-05, -3.6843e-04,  5.5773e-03,  4.1098e-02,\n",
      "        -8.0191e-04, -2.4093e-03, -2.5919e-02,  1.2519e-03, -2.3039e-03,\n",
      "        -8.6203e-03,  1.2129e-02,  1.0854e-04, -1.5088e-03, -7.4610e-02,\n",
      "         2.2519e-02, -3.8466e-02,  1.0974e-02,  6.0302e-02, -5.1620e-02,\n",
      "         1.3340e-02, -8.0559e-03,  4.1242e-04,  1.9552e-02, -7.9269e-03,\n",
      "        -8.1603e-03,  1.7111e-03,  6.7728e-03,  6.4310e-02, -1.3457e-02,\n",
      "        -7.4335e-02, -3.4480e-02, -7.3911e-04, -6.2072e-02, -2.2311e-02,\n",
      "        -1.7109e-03,  5.9918e-03, -1.9664e-03, -7.1251e-03,  2.2825e-02,\n",
      "        -4.8720e-03, -6.5003e-02, -2.1775e-03, -1.8444e-03,  7.3265e-02,\n",
      "         5.2221e-04, -1.2954e-02, -5.3259e-02, -3.7084e-02, -3.8334e-03,\n",
      "         4.3280e-02, -6.0462e-02,  7.0455e-02, -6.5359e-02,  1.0842e-03,\n",
      "         1.0533e-02,  6.1542e-03, -3.7020e-02,  1.8747e-04, -2.1195e-02,\n",
      "        -4.4640e-04,  1.5528e-03,  1.6410e-02, -6.1031e-02, -2.0254e-03,\n",
      "        -6.1408e-03,  5.8679e-03, -2.9146e-03, -1.9892e-03,  4.3533e-02,\n",
      "         1.5581e-03, -1.3258e-02, -3.4477e-03, -3.1063e-03,  1.6558e-03,\n",
      "         1.2330e-02, -1.3658e-02,  1.4830e-05,  2.3483e-03, -2.5652e-03,\n",
      "        -4.6861e-02, -3.8526e-03,  1.4891e-04,  3.5026e-03,  2.9304e-02,\n",
      "        -1.2515e-02, -1.6651e-02, -6.5505e-02, -7.0729e-03,  5.6096e-02,\n",
      "         1.6492e-02, -1.0102e-02, -5.1001e-02,  4.6134e-02,  5.9714e-02,\n",
      "         2.7749e-02, -3.9069e-03,  2.8098e-02, -4.3307e-02,  2.9125e-03,\n",
      "        -1.1555e-03, -5.4332e-04,  1.7716e-02,  3.9426e-02, -1.1650e-02,\n",
      "         5.4143e-03,  7.6668e-04, -1.4501e-02, -3.2781e-02, -1.7109e-04,\n",
      "        -4.5489e-03,  1.3235e-02, -3.1242e-02, -6.5027e-02,  4.4712e-03,\n",
      "        -8.8002e-03, -4.7278e-02,  1.5585e-02, -1.2312e-03, -7.9780e-03,\n",
      "         3.0320e-02,  5.8618e-02,  2.9539e-02, -1.0512e-02,  1.3233e-02,\n",
      "        -9.1499e-03, -1.4123e-02,  4.5389e-03, -4.5021e-02,  8.7648e-02,\n",
      "         1.5873e-02,  3.4661e-02,  2.9271e-03,  8.5943e-04,  6.3336e-02,\n",
      "         3.6434e-03,  2.7110e-02,  3.9728e-03,  1.6938e-02,  7.7805e-03,\n",
      "        -5.5892e-02,  1.3069e-02, -6.5158e-02, -1.4633e-03, -5.5059e-02,\n",
      "         7.2858e-03,  5.3833e-03,  6.2287e-02, -2.0552e-03,  5.5169e-02,\n",
      "         4.2386e-02, -6.4451e-03,  1.9792e-02,  5.1887e-02,  1.0740e-03,\n",
      "        -6.3414e-02, -7.8450e-02, -8.0298e-02,  6.7308e-03, -4.0420e-03,\n",
      "        -7.0452e-04,  1.4065e-02,  6.0994e-03,  4.5103e-03,  1.0812e-02,\n",
      "        -2.0521e-02,  6.0328e-02,  5.4586e-03, -6.6997e-02,  7.8335e-02,\n",
      "        -1.5540e-02,  5.5494e-03,  1.2440e-02, -7.8808e-02, -4.0115e-02,\n",
      "         3.3492e-04,  1.2926e-03,  2.9311e-02,  1.7346e-02,  5.1262e-02,\n",
      "        -1.8666e-03, -8.3860e-03, -1.1787e-02,  2.8252e-02, -1.7593e-02,\n",
      "        -8.7817e-02,  5.2170e-03,  4.4334e-02, -3.3100e-02,  7.3799e-02,\n",
      "        -4.1801e-02, -4.6398e-03,  5.7726e-02,  2.2281e-02,  3.2628e-02,\n",
      "         3.7614e-02,  2.2902e-02, -5.2283e-04,  2.9742e-02,  5.6447e-02,\n",
      "         4.1772e-02,  7.6728e-02,  4.9035e-02,  2.5668e-02,  2.9138e-02,\n",
      "         4.4800e-03,  1.5523e-02, -6.5518e-02, -1.5646e-03,  7.2878e-03,\n",
      "         3.4111e-02, -9.0368e-04, -3.1689e-04, -3.5873e-02,  2.4688e-02,\n",
      "        -5.3862e-04,  1.4132e-02, -1.1777e-02,  7.0576e-03, -1.1229e-02,\n",
      "        -1.0256e-02, -3.0035e-02, -3.0638e-03,  1.3067e-02,  1.0861e-02,\n",
      "         5.8566e-02, -7.6218e-03, -5.1887e-03, -4.6288e-03,  5.5355e-03,\n",
      "         7.2679e-02, -5.8685e-02,  1.8479e-02, -5.3238e-03,  6.6855e-02,\n",
      "        -1.4153e-02, -1.0367e-02,  1.9953e-02, -4.0999e-02, -2.1670e-03,\n",
      "        -4.4959e-03, -3.5326e-02,  3.8980e-02, -1.1234e-02, -3.1199e-03,\n",
      "        -1.5884e-02,  2.0611e-02,  2.4461e-03, -2.1509e-03,  5.7122e-02,\n",
      "         5.6231e-02, -6.3469e-03,  3.8378e-03,  7.6445e-03, -3.4256e-03,\n",
      "        -1.8695e-02, -4.3274e-04,  2.8806e-02, -4.9924e-02,  3.1271e-02,\n",
      "        -4.2970e-02,  2.0461e-02, -5.6234e-02,  2.5810e-05, -1.4020e-03,\n",
      "        -1.7969e-02, -1.1418e-02,  8.4572e-03,  5.4102e-03,  2.1549e-02,\n",
      "        -3.1038e-02,  4.6863e-02, -1.0834e-02,  5.6062e-02,  1.6208e-02,\n",
      "         1.5080e-02, -1.9071e-02,  5.0027e-02], device='cuda:0',\n",
      "       requires_grad=True), 'lr': 1}, {'params': Parameter containing:\n",
      "tensor([[-0.0013, -0.0381, -0.0158,  ...,  0.0244, -0.0008,  0.0240],\n",
      "        [ 0.0020,  0.0151,  0.0033,  ...,  0.0180, -0.0023,  0.0231],\n",
      "        [-0.0386,  0.0145,  0.0621,  ...,  0.0374, -0.0105, -0.0395],\n",
      "        ...,\n",
      "        [-0.0111,  0.0136,  0.0541,  ...,  0.0666,  0.0017, -0.0090],\n",
      "        [ 0.0001,  0.0024, -0.0125,  ...,  0.0046, -0.0014, -0.0079],\n",
      "        [ 0.0415,  0.0751,  0.0305,  ...,  0.0317,  0.0479,  0.0080]],\n",
      "       device='cuda:0', requires_grad=True), 'lr': 1}]\n"
     ]
    }
   ],
   "source": [
    "#-----DISCRIMINATIVE-FINE-TUNING-----#\n",
    "def disc_fine_tuning(lr):\n",
    "    parameters = []\n",
    "    list1 = []\n",
    "    previous = layer_names[2].split('.')[2]\n",
    "    lr_disc = lr\n",
    "    for idx,name in enumerate(layer_names):\n",
    "        if name.split(\".\")[0] == \"lin\":\n",
    "            for p in model.named_parameters():\n",
    "                if p[0] == name and p[1].requires_grad:\n",
    "                    parameters.append({ \"params\":p[1] ,\"lr\":lr})\n",
    "        if name.split(\".\")[1] == \"pooler\":\n",
    "            for p in model.named_parameters():\n",
    "                if p[0] == name and p[1].requires_grad:\n",
    "                    parameters.append({ \"params\":p[1] ,\"lr\":lr_disc})\n",
    "                    list1.append(p[0])\n",
    "        if name.split(\".\")[1] == \"embeddings\":\n",
    "            for p in model.named_parameters():\n",
    "                if p[0] == name and p[1].requires_grad:\n",
    "                    parameters.append({ \"params\":p[1] ,\"lr\":lr_disc})\n",
    "        if name.split(\".\")[1] == \"encoder\":\n",
    "                current = name.split('.')[3]\n",
    "                if current != previous:\n",
    "                    lr_disc = theta*lr_disc\n",
    "                previous = current\n",
    "                for p in model.named_parameters():\n",
    "                    if p[0] == name and p[1].requires_grad:\n",
    "                        parameters.append({ \"params\":p[1] ,\"lr\":lr_disc})\n",
    "                        list1.append(p[0])\n",
    "    return parameters, list1\n",
    "#-----DISCRIMINATIVE-FINE-TUNING-----#\n",
    "parameter,list1 = disc_fine_tuning(1)\n",
    "print(parameter)\n",
    "optimizer = torch.optim.Adam(parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "        param_group = parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----MISC-----#\n",
    "checkpoint = 0\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "#-----MISC-----#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(max_steps):\n",
    "    last_step = (step == max_steps - 1)\n",
    "    t0 = time.time()\n",
    "    #optimizer.zero_grad(set_to_none=True)\n",
    "    \n",
    "    #validation loss\n",
    "    if step % 250 == 1 or last_step:\n",
    "        model.eval()\n",
    "        val_loader.reset()\n",
    "        with torch.no_grad():\n",
    "            correct_acum = 0\n",
    "            val_accum = 0\n",
    "            val_loss_steps = 80\n",
    "            for val_steps in range(val_loss_steps):\n",
    "                x, y = val_loader.next_batch()\n",
    "                x,y = x.to(device), y.to(device)\n",
    "                with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "                    logits,loss = model(x,y)\n",
    "                values,ind = torch.max(logits,dim = 1)\n",
    "                correct = np.sum((torch.eq(ind.to(\"cpu\"),y.to(\"cpu\")).numpy()))\n",
    "                correct_acum = correct_acum + correct\n",
    "                val_accum = val_accum + loss.detach()\n",
    "            accuracy = correct_acum / (val_loss_steps * B)\n",
    "            val_loss = val_accum / val_loss_steps\n",
    "    \n",
    "    #save checkpoint\n",
    "    if step % 500 == 0:\n",
    "        torch.save(model.state_dict(),f\"checkpoint{checkpoint}.pt\")\n",
    "        checkpoint = checkpoint+1\n",
    "\n",
    "    #minibatch process\n",
    "    loss_accum = 0\n",
    "    model.train()\n",
    "    for mini_step in range(grad_accum_steps):\n",
    "        x, y = loader.next_batch()\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "            logits,loss = model(x,y)\n",
    "        #print(f\"loss mini_step = {loss} | ministep = {mini_step}\")\n",
    "        loss = loss / grad_accum_steps\n",
    "        loss_accum = loss_accum + loss.detach()\n",
    "        loss.backward()\n",
    "    norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 7.0)\n",
    "\n",
    "    t1 = time.time()\n",
    "    dt = t1-t0\n",
    "\n",
    "    lr = get_lr(step)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group = parameter\n",
    "    optimizer.step()\n",
    "\n",
    "torch.save(model.state_dict(),\"Final.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----OPTIMIZER-----#\n",
    "def configure_optimizers(model, weight_decay, learning_rate, device):\n",
    "    param_dict = {pn: p for pn, p in model.named_parameters()}\n",
    "    param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
    "    decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
    "    nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
    "    optim_groups = [\n",
    "        {'params': decay_params, 'weight_decay': weight_decay},\n",
    "        {'params': nodecay_params, 'weight_decay': 0.0}\n",
    "    ]\n",
    "    num_decay_params = sum(p.numel() for p in decay_params)\n",
    "    num_nodecay_params = sum(p.numel() for p in nodecay_params) \n",
    "    print(num_decay_params,num_nodecay_params)\n",
    "    fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
    "    use_fused = fused_available and device == \"cuda\"\n",
    "    print(f\"using fused AdamW: {use_fused}\")\n",
    "    optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=(0.9, 0.999), eps=1e-8, fused=use_fused)\n",
    "    return optimizer  \n",
    "  \n",
    "optimizer = configure_optimizers(model = model, weight_decay=0.05, learning_rate=6e-4, device=device)\n",
    "#-----OPTIMIZER-----#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
